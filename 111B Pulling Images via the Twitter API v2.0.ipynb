{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Define Functions to Interact with the Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import json \n",
    "import pandas as pd\n",
    "import urllib\n",
    "import os\n",
    "from os import path\n",
    "from datetime import datetime as dt\n",
    "\n",
    "# imports the twitter_secrets python file in which we store the twitter API keys\n",
    "from twitter_secrets import twitter_secrets as ts\n",
    "\n",
    "# puts the bearer token in the request header\n",
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "        \n",
    "# sets the rules on which tweets to retrieve   \n",
    "def set_rules(headers, delete, bearer_token, rules):\n",
    "    payload = {\"add\": rules}\n",
    "    response = requests.post(\n",
    "        \"https://api.twitter.com/2/tweets/search/stream/rules\",\n",
    "        headers=headers,\n",
    "        json=payload,\n",
    "    )\n",
    "    if response.status_code != 201:\n",
    "        raise Exception(\n",
    "            \"Cannot add rules (HTTP {}): {}\".format(response.status_code, response.text)\n",
    "        )\n",
    "    print(json.dumps(response.json()))\n",
    "\n",
    "# retrieves the current set of rules from the API  \n",
    "def get_rules(headers, bearer_token):\n",
    "    response = requests.get(\n",
    "        \"https://api.twitter.com/2/tweets/search/stream/rules\", headers=headers\n",
    "    )\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Cannot get rules (HTTP {}): {}\".format(response.status_code, response.text)\n",
    "        )\n",
    "    print(json.dumps(response.json()))\n",
    "    return response.json()\n",
    "\n",
    "# tells the API to delete our current rule configuration \n",
    "def delete_all_rules(headers, bearer_token, rules):\n",
    "    if rules is None or \"data\" not in rules:\n",
    "        return None\n",
    "\n",
    "    ids = list(map(lambda rule: rule[\"id\"], rules[\"data\"]))\n",
    "    payload = {\"delete\": {\"ids\": ids}}\n",
    "    response = requests.post(\n",
    "        \"https://api.twitter.com/2/tweets/search/stream/rules\",\n",
    "        headers=headers,\n",
    "        json=payload\n",
    "    )\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Cannot delete rules (HTTP {}): {}\".format(\n",
    "                response.status_code, response.text\n",
    "            )\n",
    "        )\n",
    "    print(json.dumps(response.json()))\n",
    "\n",
    "# starts the stream, iterates through the lines of the response and for each line calls the save_tweets function and the save_media_to_disk function\n",
    "def get_stream(headers, set, bearer_token, expansions, fields, save_to_disk, save_path):\n",
    "    data = []\n",
    "    response = requests.get(\n",
    "        \"https://api.twitter.com/2/tweets/search/stream\" + expansions + fields, headers=headers, stream=True,\n",
    "    )\n",
    "    print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Cannot get stream (HTTP {}): {}\".format(\n",
    "                response.status_code, response.text\n",
    "            )\n",
    "        )\n",
    "    i = 0\n",
    "    for response_line in response.iter_lines():\n",
    "        i += 1\n",
    "        if i == max_results:\n",
    "            break\n",
    "        else:\n",
    "            json_response = json.loads(response_line)\n",
    "            #print(json.dumps(json_response, indent=4, sort_keys=True))\n",
    "            try:\n",
    "                save_tweets(json_response)\n",
    "                if save_to_disk == True:\n",
    "                    save_media_to_disk(json_response, save_path)\n",
    "            except (json.JSONDecodeError, KeyError) as err:\n",
    "                # In case the JSON fails to decode, we skip this tweet\n",
    "                print(f\"{i}/{max_results}: ERROR: encountered a problem with a line of data... \\n\")\n",
    "                continue\n",
    "\n",
    "# appends information from tweets to a dataframe           \n",
    "def save_tweets(tweet):\n",
    "    #print(json.dumps(tweet, indent=4, sort_keys=True))\n",
    "    data = tweet['data']\n",
    "    includes = tweet['includes']\n",
    "    media = includes['media']\n",
    "    for line in media:\n",
    "        tweet_list.append([data['id'], line['url']])  \n",
    "\n",
    "# iterates through the media attached to a tweet and saves each media file to the specified directory\n",
    "def save_media_to_disk(tweet, save_path):\n",
    "    data = tweet['data']\n",
    "    #print(json.dumps(data, indent=4, sort_keys=True))\n",
    "    includes = tweet['includes']\n",
    "    media = includes['media']\n",
    "    for line in media:\n",
    "        media_url = line['url']\n",
    "        media_key = line['media_key']\n",
    "        pic = urllib.request.urlopen(media_url)\n",
    "        file_path = save_path + \"\\\\\" + media_key + \".jpg\"\n",
    "        \n",
    "        if not path.isfile(file_path):\n",
    "            print(file_path)\n",
    "            try:\n",
    "                with open(file_path, 'wb') as localFile:\n",
    "                    localFile.write(pic.read())\n",
    "                tweet_list.append(media_key, media_url)\n",
    "            except Exception as e:\n",
    "                print('exception when saving media url ' + media_url + ' to path: ' + file_path)\n",
    "\n",
    "# creates a new directory\n",
    "def createDir(save_path):\n",
    "    try:\n",
    "        os.makedirs(save_path)\n",
    "    except OSError:\n",
    "        print (\"Creation of the directory %s failed\" % save_path)\n",
    "        if path.exists(savepath):\n",
    "            print(\"file already exists\")\n",
    "    else:\n",
    "        print (\"Successfully created the directory %s \" % save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Define the Folder Structure for the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current working directory is C:\\Users\\Flo\\relataly-public-python-API-tutorials\n",
      "Successfully created the directory C:\\Users\\Flo\\relataly-public-python-API-tutorials\\twitter\\downloaded_media\\02052021-164036 \n"
     ]
    }
   ],
   "source": [
    "# save to disk true/false\n",
    "save_to_disk = True\n",
    " \n",
    "# saves the images to disk in a new folder path that will be created with the createDir function\n",
    "if save_to_disk == True: \n",
    "    # detect the current working directory and print it\n",
    "    base_path = os.getcwd()\n",
    "    print (\"The current working directory is %s\" % base_path)\n",
    "    img_dir = '\\\\twitter\\\\downloaded_media\\\\'\n",
    "    # the write path in which the data will be stored. If it does not yet exist, it will be created\n",
    "    now = dt.now()\n",
    "    dt_string = now.strftime(\"%d%m%Y-%H%M%S\")# ddmmYY-HMS\n",
    "    save_path = base_path + img_dir + dt_string\n",
    "    createDir(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Subscribe to the Tweet Streaming Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"data\": [{\"id\": \"1388865425992294400\", \"value\": \"cat has:images -grumpy\", \"tag\": \"cat pictures\"}, {\"id\": \"1388865425992294401\", \"value\": \"dog has:images\", \"tag\": \"dog pictures\"}], \"meta\": {\"sent\": \"2021-05-02T14:41:00.279Z\"}}\n",
      "{\"meta\": {\"sent\": \"2021-05-02T14:41:01.645Z\", \"summary\": {\"deleted\": 2, \"not_deleted\": 0}}}\n",
      "{\"data\": [{\"value\": \"dog has:images\", \"tag\": \"dog pictures\", \"id\": \"1388866121256869898\"}], \"meta\": {\"sent\": \"2021-05-02T14:41:02.800Z\", \"summary\": {\"created\": 1, \"not_created\": 0, \"valid\": 1, \"invalid\": 0}}}\n",
      "200\n",
      "1/10: ERROR: encountered a problem with a line of data... \n",
      "\n",
      "2/10: ERROR: encountered a problem with a line of data... \n",
      "\n",
      "3/10: ERROR: encountered a problem with a line of data... \n",
      "\n",
      "C:\\Users\\Flo\\relataly-public-python-API-tutorials\\twitter\\downloaded_media\\02052021-164036\\3_1388866102214549508.jpg\n",
      "exception when saving media url https://pbs.twimg.com/media/E0Y-XIcUYAQyNdY.jpg to path: C:\\Users\\Flo\\relataly-public-python-API-tutorials\\twitter\\downloaded_media\\02052021-164036\\3_1388866102214549508.jpg\n",
      "C:\\Users\\Flo\\relataly-public-python-API-tutorials\\twitter\\downloaded_media\\02052021-164036\\3_1388866102231330817.jpg\n",
      "exception when saving media url https://pbs.twimg.com/media/E0Y-XIgUcAEbqCH.jpg to path: C:\\Users\\Flo\\relataly-public-python-API-tutorials\\twitter\\downloaded_media\\02052021-164036\\3_1388866102231330817.jpg\n",
      "C:\\Users\\Flo\\relataly-public-python-API-tutorials\\twitter\\downloaded_media\\02052021-164036\\3_1388866102223015936.jpg\n",
      "exception when saving media url https://pbs.twimg.com/media/E0Y-XIeVkAAUqbv.jpg to path: C:\\Users\\Flo\\relataly-public-python-API-tutorials\\twitter\\downloaded_media\\02052021-164036\\3_1388866102223015936.jpg\n",
      "C:\\Users\\Flo\\relataly-public-python-API-tutorials\\twitter\\downloaded_media\\02052021-164036\\3_1388866102222934016.jpg\n",
      "exception when saving media url https://pbs.twimg.com/media/E0Y-XIeUUAAlq3V.jpg to path: C:\\Users\\Flo\\relataly-public-python-API-tutorials\\twitter\\downloaded_media\\02052021-164036\\3_1388866102222934016.jpg\n",
      "C:\\Users\\Flo\\relataly-public-python-API-tutorials\\twitter\\downloaded_media\\02052021-164036\\3_1388204392688627715.jpg\n",
      "exception when saving media url https://pbs.twimg.com/media/E0PkikXXsAMfaXt.jpg to path: C:\\Users\\Flo\\relataly-public-python-API-tutorials\\twitter\\downloaded_media\\02052021-164036\\3_1388204392688627715.jpg\n",
      "6/10: ERROR: encountered a problem with a line of data... \n",
      "\n",
      "C:\\Users\\Flo\\relataly-public-python-API-tutorials\\twitter\\downloaded_media\\02052021-164036\\3_1388866123807051782.jpg\n",
      "exception when saving media url https://pbs.twimg.com/media/E0Y-YY4X0AY2rjd.jpg to path: C:\\Users\\Flo\\relataly-public-python-API-tutorials\\twitter\\downloaded_media\\02052021-164036\\3_1388866123807051782.jpg\n",
      "8/10: ERROR: encountered a problem with a line of data... \n",
      "\n",
      "9/10: ERROR: encountered a problem with a line of data... \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>preview_image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1388866111941140481</td>\n",
       "      <td>https://pbs.twimg.com/media/E0Y-XIcUYAQyNdY.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1388866111941140481</td>\n",
       "      <td>https://pbs.twimg.com/media/E0Y-XIgUcAEbqCH.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1388866111941140481</td>\n",
       "      <td>https://pbs.twimg.com/media/E0Y-XIeVkAAUqbv.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1388866111941140481</td>\n",
       "      <td>https://pbs.twimg.com/media/E0Y-XIeUUAAlq3V.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1388866115401568260</td>\n",
       "      <td>https://pbs.twimg.com/media/E0PkikXXsAMfaXt.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1388866125010702338</td>\n",
       "      <td>https://pbs.twimg.com/media/E0Y-YY4X0AY2rjd.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweetid                                preview_image_url\n",
       "0  1388866111941140481  https://pbs.twimg.com/media/E0Y-XIcUYAQyNdY.jpg\n",
       "1  1388866111941140481  https://pbs.twimg.com/media/E0Y-XIgUcAEbqCH.jpg\n",
       "2  1388866111941140481  https://pbs.twimg.com/media/E0Y-XIeVkAAUqbv.jpg\n",
       "3  1388866111941140481  https://pbs.twimg.com/media/E0Y-XIeUUAAlq3V.jpg\n",
       "4  1388866115401568260  https://pbs.twimg.com/media/E0PkikXXsAMfaXt.jpg\n",
       "5  1388866125010702338  https://pbs.twimg.com/media/E0Y-YY4X0AY2rjd.jpg"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the max number of tweets that will be returned\n",
    "max_results = 10\n",
    "\n",
    "# you can adjust the rules if needed\n",
    "search_rules = [\n",
    "    {\"value\": \"dog has:images\", \n",
    "     \"tag\": \"dog pictures\", \n",
    "     \"lang\": \"en\"},\n",
    "]\n",
    "\n",
    "# these are the fields that will be delivered with the response\n",
    "media_fields = \"&media.fields=duration_ms,height,media_key,preview_image_url,public_metrics,type,url,width\"\n",
    "\n",
    "# we will retrieve the tweet object extended by the media object\n",
    "expansions = \"?expansions=attachments.media_keys\"\n",
    "tweet_list = []\n",
    "\n",
    "bearer_token = ts.BEARER_TOKEN\n",
    "headers = create_headers(bearer_token)\n",
    "rules = get_rules(headers, bearer_token)\n",
    "delete = delete_all_rules(headers, bearer_token, rules)\n",
    "set = set_rules(headers, delete, bearer_token, search_rules)\n",
    "get_stream(headers, set, bearer_token, expansions, media_fields, save_to_disk, save_path)\n",
    "\n",
    "df = pd.DataFrame (tweet_list, columns = ['tweetid', 'preview_image_url'])\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
